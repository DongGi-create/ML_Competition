{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Import necessary libraries"
      ],
      "metadata": {
        "id": "3Y4-_hkw_qNu"
      },
      "id": "3Y4-_hkw_qNu"
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n"
      ],
      "metadata": {
        "id": "gGa6SsWB_tUV"
      },
      "id": "gGa6SsWB_tUV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download and extract the Caltech-256 dataset"
      ],
      "metadata": {
        "id": "rZWN9mk5_tdr"
      },
      "id": "rZWN9mk5_tdr"
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://caltech256-bucket.s3.amazonaws.com/256_ObjectCategories.tar\n",
        "!tar -xf 256_ObjectCategories.tar"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fB_lx7wf_tl6",
        "outputId": "a8c40cd3-b7ba-4eea-8d90-98cf78acbe60"
      },
      "id": "fB_lx7wf_tl6",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-05-25 13:26:47--  https://caltech256-bucket.s3.amazonaws.com/256_ObjectCategories.tar\n",
            "Resolving caltech256-bucket.s3.amazonaws.com (caltech256-bucket.s3.amazonaws.com)... 3.5.25.92, 54.231.134.105, 52.217.39.60, ...\n",
            "Connecting to caltech256-bucket.s3.amazonaws.com (caltech256-bucket.s3.amazonaws.com)|3.5.25.92|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1183006720 (1.1G) [application/x-tar]\n",
            "Saving to: ‘256_ObjectCategories.tar’\n",
            "\n",
            "256_ObjectCategorie 100%[===================>]   1.10G  15.4MB/s    in 86s     \n",
            "\n",
            "2023-05-25 13:28:14 (13.1 MB/s) - ‘256_ObjectCategories.tar’ saved [1183006720/1183006720]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "running ResNeXt50"
      ],
      "metadata": {
        "id": "8z7j8E1n_tu6"
      },
      "id": "8z7j8E1n_tu6"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0d4b487b",
      "metadata": {
        "scrolled": true,
        "id": "0d4b487b",
        "outputId": "ca5234cb-6227-4168-96e7-4daa9af22ea3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "Train Loss: 2.1581 | Train Accuracy: 0.5855\n",
            "Epoch 1/10\n",
            "Train Loss: 2.1581 | Train Accuracy: 0.5855\n",
            "Test Loss: 0.6250 | Test Accuracy: 0.8500\n",
            "Epoch 2/10\n",
            "Train Loss: 0.4676 | Train Accuracy: 0.9004\n",
            "Epoch 2/10\n",
            "Train Loss: 0.4676 | Train Accuracy: 0.9004\n",
            "Test Loss: 0.4453 | Test Accuracy: 0.8873\n",
            "Epoch 3/10\n",
            "Train Loss: 0.1710 | Train Accuracy: 0.9631\n",
            "Epoch 3/10\n",
            "Train Loss: 0.1710 | Train Accuracy: 0.9631\n",
            "Test Loss: 0.4359 | Test Accuracy: 0.8919\n",
            "Epoch 4/10\n",
            "Train Loss: 0.0784 | Train Accuracy: 0.9835\n",
            "Epoch 4/10\n",
            "Train Loss: 0.0784 | Train Accuracy: 0.9835\n",
            "Test Loss: 0.4541 | Test Accuracy: 0.8894\n",
            "Epoch 5/10\n",
            "Train Loss: 0.0522 | Train Accuracy: 0.9887\n",
            "Epoch 5/10\n",
            "Train Loss: 0.0522 | Train Accuracy: 0.9887\n",
            "Test Loss: 0.4936 | Test Accuracy: 0.8896\n",
            "Epoch 6/10\n",
            "Train Loss: 0.0431 | Train Accuracy: 0.9903\n",
            "Epoch 6/10\n",
            "Train Loss: 0.0431 | Train Accuracy: 0.9903\n",
            "Test Loss: 0.4957 | Test Accuracy: 0.8878\n",
            "Epoch 7/10\n",
            "Train Loss: 0.0366 | Train Accuracy: 0.9910\n",
            "Epoch 7/10\n",
            "Train Loss: 0.0366 | Train Accuracy: 0.9910\n",
            "Test Loss: 0.5220 | Test Accuracy: 0.8891\n",
            "Epoch 8/10\n",
            "Train Loss: 0.0332 | Train Accuracy: 0.9921\n",
            "Epoch 8/10\n",
            "Train Loss: 0.0332 | Train Accuracy: 0.9921\n",
            "Test Loss: 0.5869 | Test Accuracy: 0.8804\n",
            "Epoch 9/10\n",
            "Train Loss: 0.0311 | Train Accuracy: 0.9925\n",
            "Epoch 9/10\n",
            "Train Loss: 0.0311 | Train Accuracy: 0.9925\n",
            "Test Loss: 0.5780 | Test Accuracy: 0.8801\n",
            "Epoch 10/10\n",
            "Train Loss: 0.0318 | Train Accuracy: 0.9924\n",
            "Epoch 10/10\n",
            "Train Loss: 0.0318 | Train Accuracy: 0.9924\n",
            "Test Loss: 0.5615 | Test Accuracy: 0.8909\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import glob\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision import models, transforms\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from PIL import Image\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Set the seed for reproducibility\n",
        "np.random.seed(42)\n",
        "torch.manual_seed(42)\n",
        "\n",
        "# Define dataset_path and load the data\n",
        "dataset_path = './256_ObjectCategories'\n",
        "all_images = glob.glob(f'{dataset_path}/*/*.jpg')\n",
        "all_labels = [os.path.basename(os.path.dirname(img)) for img in all_images]\n",
        "\n",
        "# Train-test split (4:1 test_size=0.2)\n",
        "train_images, test_images, train_labels, test_labels = train_test_split(all_images, all_labels, test_size=0.2, random_state=42, stratify=all_labels)\n",
        "\n",
        "# Define custom dataset\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, images, labels, transform=None):\n",
        "        self.images = images\n",
        "        labels = [int(label[:3])-1 for label in labels]\n",
        "        self.labels = labels\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.images[idx]\n",
        "        label = self.labels[idx]\n",
        "        image = Image.open(img_path).convert('RGB')\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label\n",
        "\n",
        "# Define transformations\n",
        "img_size = 299  # ResNeXt requires input size of (299, 299)\n",
        "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((img_size, img_size)),\n",
        "    transforms.ToTensor(),\n",
        "    normalize\n",
        "])\n",
        "\n",
        "# Create custom datasets\n",
        "train_dataset = CustomDataset(train_images, train_labels, transform=transform)\n",
        "test_dataset = CustomDataset(test_images, test_labels, transform=transform)\n",
        "\n",
        "# Create data loaders\n",
        "batch_size = 8\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# Create ResNeXt model\n",
        "model = models.resnext50_32x4d(weights='ResNeXt50_32X4D_Weights.IMAGENET1K_V2')\n",
        "num_classes = len(np.unique(all_labels))\n",
        "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
        "\n",
        "# Define device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = model.to(device)\n",
        "\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.00005)\n",
        "\n",
        "# Train the model\n",
        "epochs = 10\n",
        "for epoch in range(epochs):\n",
        "    train_loss = 0.0\n",
        "    train_accuracy = 0.0\n",
        "    model.train()\n",
        "\n",
        "    for batch_x, batch_y in train_loader:\n",
        "        \n",
        "        batch_x = batch_x.to(device)\n",
        "        batch_y = batch_y.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(batch_x)\n",
        "        loss = criterion(outputs, batch_y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "       \n",
        "        train_loss += loss.item()\n",
        "        \n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "       \n",
        "        train_accuracy += (predicted == batch_y).sum().item()\n",
        "    \n",
        "    train_loss /= len(train_loader)\n",
        "    train_accuracy /= len(train_dataset)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{epochs}\")\n",
        "    print(f\"Train Loss: {train_loss:.4f} | Train Accuracy: {train_accuracy:.4f}\")\n",
        "    # Evaluate the model\n",
        "    model.eval()\n",
        "    test_loss = 0.0\n",
        "    test_accuracy = 0.0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch_x, batch_y in test_loader:\n",
        "            batch_x = batch_x.to(device)\n",
        "            batch_y = batch_y.to(device)\n",
        "\n",
        "            outputs = model(batch_x)\n",
        "            loss = criterion(outputs, batch_y)\n",
        "\n",
        "            test_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            test_accuracy += (predicted == batch_y).sum().item()\n",
        "\n",
        "        test_loss /= len(test_loader)\n",
        "        test_accuracy /= len(test_dataset)\n",
        "\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{epochs}\")\n",
        "    print(f\"Train Loss: {train_loss:.4f} | Train Accuracy: {train_accuracy:.4f}\")\n",
        "    print(f\"Test Loss: {test_loss:.4f} | Test Accuracy: {test_accuracy:.4f}\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.16"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}