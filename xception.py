# -*- coding: utf-8 -*-
"""Xception.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ODQX6yb3Pwyk84dL0osfPuhXhRux1__1

import labraries
"""

import os
import glob
import numpy as np
import tensorflow as tf
from tensorflow.keras.models import Model
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split
from tensorflow.keras.applications.xception import Xception
from tensorflow.keras.layers import GlobalAveragePooling2D, Dense
from tensorflow.keras.preprocessing.image import ImageDataGenerator

"""Download and Extract Caltech-256 data"""

!wget https://caltech256-bucket.s3.amazonaws.com/256_ObjectCategories.tar
!tar -xf 256_ObjectCategories.tar

"""define dataset_path and load the data"""

dataset_path = './256_ObjectCategories'
all_images = glob.glob(f'{dataset_path}/*/*.jpg')
all_labels = [os.path.basename(os.path.dirname(img)) for img in all_images]

# Train-test split (4:1 test_size=0.2)
train_images, test_images, train_labels, test_labels = train_test_split(all_images, all_labels, test_size=0.2, random_state=42, stratify=all_labels)

"""Create custom dataset"""

img_size = 224
batch_size = 32
num_classes = 257

def preprocess_image(img):
    img = tf.keras.preprocessing.image.load_img(img, target_size=(img_size, img_size))
    img = tf.keras.preprocessing.image.img_to_array(img)
    img = tf.keras.applications.xception.preprocess_input(img)
    return img

def train_data_generator(images, labels, batch_size):
    encoder = LabelEncoder()
    encoded_labels = encoder.fit_transform(labels)
    num_classes = len(encoder.classes_)
    
    while True:
        idx = np.random.permutation(len(images))
        for i in range(0, len(images), batch_size):
            batch_idx = idx[i:i+batch_size]
            batch_images = [tf.keras.preprocessing.image.load_img(img, target_size=(img_size, img_size)) for img in np.array(images)[batch_idx]]
            batch_x = np.array([tf.keras.preprocessing.image.img_to_array(img) for img in batch_images]) / 255.0
            batch_y = tf.keras.utils.to_categorical(encoded_labels[batch_idx], num_classes)
            yield batch_x, batch_y

def test_data_generator(images, labels, batch_size):
    encoder = LabelEncoder()
    encoded_labels = encoder.fit_transform(labels)
    num_classes = len(encoder.classes_)
    
    while True:
        idx = np.arange(len(images))
        for i in range(0, len(images), batch_size):
            batch_idx = idx[i:i+batch_size]
            batch_images = [tf.keras.preprocessing.image.load_img(img, target_size=(img_size, img_size)) for img in np.array(images)[batch_idx]]
            batch_x = np.array([tf.keras.preprocessing.image.img_to_array(img) for img in batch_images]) / 255.0
            batch_y = tf.keras.utils.to_categorical(encoded_labels[batch_idx], num_classes)
            yield batch_x, batch_y

train_generator = train_data_generator(train_images, train_labels, batch_size)
test_generator = test_data_generator(test_images, test_labels, batch_size)

print(len(train_images))
print(len(test_images))

"""Build Xception"""

# Xception 모델 로드 및 커스텀 분류기 추가
base_model = Xception(weights='imagenet', include_top=False, input_shape=(img_size, img_size, 3))
x = GlobalAveragePooling2D()(base_model.output)
x = Dense(256, activation='relu')(x)
outputs = Dense(num_classes, activation='softmax')(x)
model = Model(inputs=base_model.input, outputs=outputs)

# 모델 컴파일
model.compile(optimizer=tf.keras.optimizers.Adam(), loss='categorical_crossentropy', metrics=['accuracy'])

"""train Xception"""

# 학습 및 평가
epochs = 10
steps_per_epoch = len(train_images) // batch_size
validation_steps = len(test_images) // batch_size

history = model.fit(train_generator, epochs=epochs, steps_per_epoch=steps_per_epoch, validation_data=test_generator, validation_steps=validation_steps, verbose=1)

"""calculate test_accuracy"""

# 정확도 판단
test_loss, test_accuracy = model.evaluate(test_generator, steps=validation_steps)
print(f"Test loss: {test_loss:.4f}")
print(f"Test accuracy: {test_accuracy:.4f}")